{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5 - Convolutioneel neuraal netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 17:31:14.422987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-26 17:31:14.423005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (50000, 32, 32, 3)\n",
      "y_train shape (50000, 1)\n",
      "x_test shape (10000, 32, 32, 3)\n",
      "y_test shape (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(\"x_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"x_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor one hot encoding uit over de target values, en laten we ook de dataset normaliseren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encodign over de targets heen\n",
    "Y_train = utils.to_categorical(y_train, 10)\n",
    "Y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "# normaliseren van de data\n",
    "X_train = utils.normalize(X_train)\n",
    "X_test = utils.normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor het berekenen van de output dimension kunnen we de volgende formule gebruiken.\n",
    "\n",
    "    Output height = (Input height + padding height top + padding height bottom - kernel height) / (stride height) + 1 \n",
    "    \n",
    "    Output width = (Output width + padding width right + padding width left - kernel width) / (stride width) + 1\n",
    "\n",
    "Aangezien het voor dit dataset altijd uitkomt naar een vierkant hoeven we maar 1 te gebruiken om de size te weten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 17:31:16.593780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-26 17:31:16.593803: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-26 17:31:16.593817: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Barry-EOS): /proc/driver/nvidia/version does not exist\n",
      "2022-03-26 17:31:16.593998: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "# Layer 1 (CN)\n",
    "# mijn hoop is door de size voor nu nog het zelfe de te houden dat we meer detail kunnen opvangen.\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", input_shape=(32,32,3)))\n",
    "cnn.add(BatchNormalization(axis=-1))\n",
    "cnn.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "# Layer 2 (CN)\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(2, 2)))\n",
    "cnn.add(BatchNormalization(axis=-1))\n",
    "cnn.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 3 (CN)\n",
    "cnn.add(Conv2D(filters=16, kernel_size=(3, 3)))\n",
    "cnn.add(BatchNormalization(axis=-1))\n",
    "cnn.add(Activation(\"relu\"))\n",
    "cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn.add(Flatten())\n",
    "\n",
    "# Layer 4 (FC)\n",
    "cnn.add(Dense(512))\n",
    "cnn.add(BatchNormalization(axis=-1))\n",
    "cnn.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 5 (FC)\n",
    "cnn.add(Dense(200))\n",
    "cnn.add(BatchNormalization(axis=-1))\n",
    "cnn.add(Activation(\"relu\"))\n",
    "\n",
    "# Layer 6 (FC)\n",
    "cnn.add(Dense(10))\n",
    "cnn.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Hieronder kunnen we dan de summary zien van het gehele netwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 15, 15, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 15, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 16)        4624      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 13, 13, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 6, 6, 16)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               295424    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               102600    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 200)              800       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 417,970\n",
      "Trainable params: 416,386\n",
      "Non-trainable params: 1,584\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilen\n",
    "Ook hier moeten we het model gaan compilen met een loss function en optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainen en evalueren \n",
    "Hierna kunnen we het model gaan fitten. Dit gaan we op een beetje een apparte manier doen aangezioen we de data willen over lappen met de evalueren van de test set voor overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 17:31:17.083572: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 19s 23ms/step - loss: 1.5668 - accuracy: 0.4391 - val_loss: 1.8076 - val_accuracy: 0.3684\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.2510 - accuracy: 0.5590 - val_loss: 1.8784 - val_accuracy: 0.3670\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 1.0829 - accuracy: 0.6193 - val_loss: 1.8644 - val_accuracy: 0.3806\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 18s 22ms/step - loss: 0.9491 - accuracy: 0.6671 - val_loss: 1.5125 - val_accuracy: 0.5064\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.8237 - accuracy: 0.7099 - val_loss: 1.7650 - val_accuracy: 0.4586\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.7002 - accuracy: 0.7548 - val_loss: 1.6898 - val_accuracy: 0.4877\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.5811 - accuracy: 0.7983 - val_loss: 2.3541 - val_accuracy: 0.4461\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.4815 - accuracy: 0.8341 - val_loss: 1.9454 - val_accuracy: 0.4914\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3975 - accuracy: 0.8632 - val_loss: 2.1562 - val_accuracy: 0.4467\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.3285 - accuracy: 0.8859 - val_loss: 1.7563 - val_accuracy: 0.5497\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.2801 - accuracy: 0.9045 - val_loss: 2.5629 - val_accuracy: 0.4427\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.2548 - accuracy: 0.9119 - val_loss: 2.5940 - val_accuracy: 0.4959\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 18s 23ms/step - loss: 0.2237 - accuracy: 0.9230 - val_loss: 2.6059 - val_accuracy: 0.4791\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.2045 - accuracy: 0.9284 - val_loss: 2.2245 - val_accuracy: 0.5305\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.1946 - accuracy: 0.9335 - val_loss: 2.5881 - val_accuracy: 0.4983\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1747 - accuracy: 0.9391 - val_loss: 2.4159 - val_accuracy: 0.5004\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1623 - accuracy: 0.9441 - val_loss: 2.2638 - val_accuracy: 0.5517\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1577 - accuracy: 0.9454 - val_loss: 2.6433 - val_accuracy: 0.5513\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1574 - accuracy: 0.9443 - val_loss: 2.3423 - val_accuracy: 0.5571\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.1454 - accuracy: 0.9506 - val_loss: 2.4539 - val_accuracy: 0.5292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcadc5c6320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, Y_train, batch_size=64, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=tensorboard_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 4. Conclussie\n",
    "\n",
    "Ook hier kunnen we kijken hoe goed de resultaten zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende data heb ik verzameld van de het trainen van het netwerk, voor het verzamelen van de data heb ik tensorboard gebruikt vandaar dat er ook wat extra code voor callbacks staan\n",
    "\n",
    "<img src=\"Screenshot_20220326_174414.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay door het model te trainen en dan nog te evalueren kunnen we concludderen dat het model Zeer erg overfit is en geen goed model is geworden.\\\n",
    "Ik zou kunnen proberen om een ander architect te maken die beter werkt maar om eerlijk te zijn weet ik niet zo heel snel wat ik zou moeten veranderen om een beter werkend netwerk te krijgen.\\\n",
    "En ik moet ok nog de opdrachten van HPP maken."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
